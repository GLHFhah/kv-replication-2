# Распределенное key-value хранилище с репликацией (часть 2)

В этом задании вам предстоит усовершенствовать key-value хранилище с репликацией из предыдущего ДЗ. 

Из-за одновременных операций записи и отказов изменения могут приходить на узлы хранилища в разном порядке или теряться. В результате на разных репликах могут оказаться несколько версий значения ключа. Когда при чтении реплики возвращают разные значения, необходимо понять, какое из них вернуть клиенту. Аналогично при записи надо понять, является ли пришедшее значение более "новым", чем хранимое сейчас. В конечном счете мы хотим, чтобы значения на всех репликах оказались одинаковыми. В предыдущей версии хранилища вы решали эту проблему используя стратегию _last write wins (LWW)_. А именно, с каждой операцией записи и соответствующим значением ключа связано время записи, и из двух значений выбирается то, которое было записано позднее, а другое отбрасывается.

Стратегия LWW обладает следующими недостатками. Во-первых, в случае когда несколько клиентов одновременно пишут по одному ключу, даже если у всех клиентов запись прошла успешно в конечном итоге в хранилище останется значение только одного клиента, а записи других будут молча отброшены. Также надо как-то разрешать ситуации, когда времена операций совпадают. Во-вторых, даже малейшие отклонения в синхронизации часов между узлами могут приводить к незаметной потере неодновременных записей. Например, будут пропадать обновления ключа сделанные с узла с запаздывающими часами (см. пример из лекции 10). Эти проблемы связаны с тем, что LWW не позволяет отслеживать и учитывать причинные зависимости между операциями записи. А именно - отличать одновременные операции (A и B независимо изменяют значение ключа) от связанных отношением happened-before (запись B произошла после записи A) и сохранять причинный порядок.

Вам требуется избавиться от описанных проблем, заменив LWW на использование [векторов версий](https://pages.cs.wisc.edu/~remzi/Classes/739/Papers/parker83detection.pdf), аналогично тому как это сделано в [Dynamo](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf). Ваша реализация должна уметь определять, когда две версии значения ключа связаны логически (одна является потомком другой и можно оставить более свежую), а когда нет и требуется разрешение конфликта. Если обнаружен конфликт, то по-умолчанию надо хранить и возвращать клиенту все такие версии значения ключа.

Как и ранее, операции на чтение и запись должны выполняться с кворумами, размеры которых указывает клиент при отправке операции. Запрос на выполнение операции может быть сделан локально с любого узла. В прошлом ДЗ рассылкой запроса по репликам занимался непосредственно узел-источник запроса. В данном задании операции записи должны координироваться одной из реплик ключа (см. статью про Dynamo), чтобы уменьшить размер векторов версий. Поэтому если запрос на запись поступил узлу, не являющемуся репликой для ключа, то он должен быть переслан одной из реплик (например, первой в списке).

Помимо обнаружения конфликтов, для указанных ниже типов ключей надо реализовать автоматическое разрешение конфликтов. В этих ключах хранятся корзины с покупками в виде строки, содержащей список товаров, разделенных запятой (для простоты опустим учёт количества каждого товара). При чтении и записи такого ключа клиенту всегда возвращается только одно значение. 

- Для ключей с префиксом `CART` надо реализовать стратегию разрешения конфликта, описанную в статье про Dynamo, — итоговое значение содержит все товары из обеих версий корзины. Минусом такой стратегии является возможность появления в корзине ранее удаленных товаров.
- Для ключей с префиксом `XCART` надо реализовать стратегию разрешения конфликта, которая лишена недостатка предыдущей, например на основе [Observed-Remove Set (ORSet) CRDT](https://bartoszsypytkowski.com/the-state-of-a-state-based-crdts/).

## Реализация

Для реализации и тестирования решения используется фреймворк AnySystem (см. материалы первого семинара). В папке `solution` размещена заготовка для решения [node.py](solution/node.py). Вам надо доработать реализацию класса `StorageNode` так, чтобы проходили все тесты. Часть, связанную с репликацией, нужно взять из решения прошлого ДЗ.

При инициализации узлу передается его уникальный id, а также список id всех узлов в системе.

Узел должен поддерживать обработку следующих локальных сообщений (форматы запросов и ответов см. в заготовке), повторяющих прошлое ДЗ за исключением следующих важных отличий:
- _GET(key, quorum)_ - теперь может возвращать несколько значений (версий записи) и произвольную строку с контекстом, где можно передать вектор версий (см. статью про Dynamo),
- _PUT(key, value, quorum, metadata)_ - теперь также может принимать контекст изменяемой версии данных и возвращать несколько значений (в случае обнаружения конфликта при записи), а также соответствующий им контекст,
- _DELETE(key, quorum, metadata)_ - опустим в этом задании, так как ёё можно реализовать через _PUT_.

Для взаимодействия между узлами вы можете использовать любые собственные типы сообщений.

Аналогично прошлому ДЗ, для вычисления реплик по ключу используйте функцию `get_key_replicas()` из заготовки (использовать другую функцию не следует, так как это влияет на тесты).

**Важно!** В своей реализации вы больше не можете опираться на время, доступное через `ctx.time()`, так как теперь оно не синхронизовано между узлами.

**Запрещается** использовать любые формы "общей памяти" для всех узлов, например через атрибуты класса. У каждого узла должно быть отдельное состояние, и все взаимодействия должны идти через сообщения, так как это происходит к реальной распределенной системе.

## Тестирование

### Локальное тестирование

Тесты находятся в папке `tests`. Есть два варианта их запуска.

Рекомендуемый вариант запуска тестов - через готовый Docker-образ. В этом случае используемое окружение будет аналогично тестирующей системе. Для запуска тестов выполните команду:

```commandline
python3 ../cli.py test [ЗДЕСЬ МОЖНО УКАЗАТЬ ОПЦИИ]
```

Вы также можете запустить тесты, скомпилировав их локально с помощью компилятора Rust. Такой вариант может быть удобен, если вы хотите лучше изучить или доработать тесты. Скомпилируйте тесты с помощью команды `cargo install --path tests`. Для запуска тестов выполните команду:

```commandline
distsys-kv-replication-2 [ЗДЕСЬ МОЖНО УКАЗАТЬ ОПЦИИ]
```

Запустить только один из тестов можно с помощью опции `-t`. По умолчанию вывод тестов не содержит трассы (последовательности событий во время выполнения каждого из тестов), а только финальную сводку. Включить вывод трасс можно с помощью флага `-d`. Все доступные опции можно посмотреть с помощью флага `-h`.

Если тесты "MC ..." выполняются очень долго, то вы можете временно отключить их с помощью флага `--disable-mc-tests`, чтобы было проще проверять решение на других тестах. Если эти тесты не проходят из-за превышения лимита времени выполнения (2 минуты), то это значит, что ваша реализация создает слишком много сообщений или таймеров, скорее всего избыточных. В этом случае рекомендуется доработать решение, чтобы избавиться от избыточности.

Если вы найдете ошибки или требования из условий, которые не покрывают наши тесты, то вы можете получить за это бонусные баллы. Подробности [здесь](https://forms.gle/GngHr4jWweEKrf4M6).

### Проверка в тестирующей системе

Отправьте ваше решение в тестирующую систему следуя [инструкции](../readme.md) и дождитесь результатов.

## Оценивание

Компоненты задания и их вклад в оценку:
1. Отслеживание зависимостей с помощью векторов версий (тесты BASIC, MC EMPTY SYSTEM, MC BASIC, STALE REPLICA, SLOPPY QUORUM, MC SLOPPY QUORUM...) - 4 балла (без прохождения этой группы остальные **не засчитываются**).
2. Обнаружение конфликтов с помощью векторов версий (тесты ...CONCURRENT WRITES..., DIVERGED REPLICAS, PARTITIONED CLIENTS) - 3 балла (по 1 баллу за каждый тип тестов).
3. Корзина с простым разрешением конфликтов (тесты SHOPPING CART..., MC CONCURRENT CART) - 1 балл.
4. Корзина с продвинутым разрешением конфликтов (тесты SHOPPING XCART..., MC CONCURRENT XCART) - 2 балла.
5. Отчёт с описанием вашего решения в файле `solution/readme.md`. **При отсутствии отчёта проверка производиться не будет.**

## Рекомендации

Рекомендуемый порядок реализации решения:

- Сначала перенесите ваше решение прошлого ДЗ на новый интерфейс операций _GET_ и _PUT_, возвращая произвольный контекст (а _DELETE_ можно убрать)
  - Из-за рассинхронизации часов на узлах, перенесенное решение скорее всего не будет проходить первую группу тестов
  - Посмотрите с помощью отладочного вывода как ломается LWW в таких условиях
- Реализуйте пересылку запросов на запись реплике-координатору
  - Если запрос поступил на реплику, то можно использовать её как координатора
- Реализуйте векторы версий и замените ими LWW. Это самая трудоемкая часть, стоящая в итоге 7 баллов.
  - Для начала реализуйте хранение, передачу (через контекст) и обновление векторов
  - После этого добейтесь прохождения теста _BASIC_ за счёт определения более старой версии данных из двух
  - После этого добейтесь прохождения теста _DIVERGED REPLICAS_ за счёт определения конфликтов и выдачи всех таких значений клиенту 
- Для прохождения тестов _CONCURRENT WRITES..._ надо учитывать возможность прихода на реплику двух операций записи с одним контекстом (вектором версий)
  - Операцию с устаревшим контекстом надо считать конфликтом с пришедшей первой
  - Клиенту, отправившему эту операцию, надо вернуть оба значения в values (в context имеет смысл передать оба вектора версий или максимум из них)
- После этого должно быть несложно закрыть остальные тесты в первых двух группах
- Реализуйте корзину с простым разрешением конфликтов
  - Конфликт вы уже обнаруживаете, осталось только реализовать слияние конфликтующих значений в одно перед отправкой клиенту
- Реализуйте корзину с продвинутым разрешением конфликтов
